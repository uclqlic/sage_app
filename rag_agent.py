import os
import json
import faiss
import numpy as np
from openai import OpenAI
from embedding_model import LocalEmbeddingModel

# åŠ è½½äººç‰©è®¾å®š
def load_personas():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    persona_path = os.path.join(current_dir, "personas.json")
    if not os.path.exists(persona_path):
        raise FileNotFoundError(f"æ— æ³•æ‰¾åˆ° personas.json æ–‡ä»¶ï¼š{persona_path}")
    with open(persona_path, "r", encoding="utf-8") as f:
        return json.load(f)

personas = load_personas()

# ç›´æ¥ä»ç¯å¢ƒå˜é‡ä¸­è·å– OpenAI API Key
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("æœªåœ¨ç¯å¢ƒå˜é‡ä¸­æ‰¾åˆ° OPENAI_API_KEY")

client = OpenAI(api_key=api_key)

class RAGAgent:
    def __init__(self, persona="å­”å­"):
        self.embedder = LocalEmbeddingModel()
        self.index = faiss.IndexFlatL2(self.embedder.dim)
        self.documents = []  # [(text, metadata)]
        self.persona = persona
        self.history = []

        # âœ… æ·»åŠ é»˜è®¤æ–‡æ¡£ï¼Œé¿å…ç©º index æŠ¥é”™
        self.add_documents([
            ("é“å¯é“ï¼Œéå¸¸é“ï¼›åå¯åï¼Œéå¸¸åã€‚", {"title": "é“å¾·ç»", "chapter_title": "ç¬¬ä¸€ç« "}),
            ("å­¦è€Œæ—¶ä¹ ä¹‹ï¼Œä¸äº¦è¯´ä¹ï¼Ÿ", {"title": "è®ºè¯­", "chapter_title": "å­¦è€Œç¯‡"})
        ])

    def add_documents(self, docs):
        embeddings = [self.embedder.embed_text(text) for text, _ in docs]
        self.index.add(np.array(embeddings, dtype="float32"))
        self.documents.extend(docs)

    def retrieve(self, query, top_k=5):
        if self.index.ntotal == 0:
            return []
        embedding = self.embedder.embed_text(query).astype("float32").reshape(1, -1)
        _, indices = self.index.search(embedding, top_k)
        return [self.documents[i] for i in indices[0] if i < len(self.documents)]

    def ask(self, question):
        context_pairs = self.retrieve(question)

        persona_data = personas.get(self.persona)
        if not persona_data:
            raise ValueError(f"è§’è‰² {self.persona} ä¸å­˜åœ¨")

        system_prompt = persona_data["system_prompt"]

        # æ„é€ å¼•ç”¨æ®µ
        quote_blocks = ""
        for text, meta in context_pairs:
            book = meta.get("title", "æœªçŸ¥ä¹¦ç±").replace(".md", "").replace(".pdf", "")
            chapter = meta.get("chapter_title", "æœªçŸ¥ç« èŠ‚")
            quote_blocks += f"> {text.strip()}\n> â€”â€”ã€Š{book}ã€‹Â·{chapter}\n\n"

        user_prompt = f"""
ã€å¼•ç”¨èµ„æ–™ã€‘ï¼š
{quote_blocks}

ã€ç”¨æˆ·é—®é¢˜ã€‘ï¼š{question}
è¯·ä»¥ä½ çš„é£æ ¼å›ç­”ï¼Œå¼•ç”¨èµ„æ–™å†…å®¹ï¼Œä¸å¾—ç¼–é€ ã€‚
"""

        messages = [{"role": "system", "content": system_prompt}]
        for q, a in self.history[-5:]:
            messages.append({"role": "user", "content": q})
            messages.append({"role": "assistant", "content": a})
        messages.append({"role": "user", "content": user_prompt})

        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.7
        )

        answer = response.choices[0].message.content.strip()
        self.history.append((question, answer))
        return answer

# âœ… CLI æµ‹è¯•å…¥å£ï¼ˆå¯é€‰ï¼‰
if __name__ == "__main__":
    agent = RAGAgent()
    while True:
        question = input("\nğŸ¤– è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼ˆè¾“å…¥ q é€€å‡ºï¼‰ï¼š\n> ")
        if question.lower() in ['q', 'quit', 'exit']:
            break
        role_id = input("è¯·é€‰æ‹©è§’è‰²ï¼ˆå­”å­ / è€å­ / å—æ€€ç‘¾ï¼‰ï¼š\n> ") or "å­”å­"
        agent.persona = role_id
        answer = agent.ask(question)
        print(f"\nğŸ’¡ å›ç­”ï¼ˆ{role_id}ï¼‰ï¼š\n{answer}")
