import json
import chromadb
import streamlit as st
from openai import OpenAI
from embedding_model import LocalEmbeddingModel

# ===== åŠ è½½äººç‰© personas.json æ–‡ä»¶ =====
def load_personas():
    current_dir = os.path.dirname(os.path.abspath(__file__))
    persona_path = os.path.join(current_dir, "personas.json")
    if not os.path.exists(persona_path):
        raise FileNotFoundError(f"æ— æ³•æ‰¾åˆ° personas.json æ–‡ä»¶ï¼š{persona_path}")
    with open(persona_path, "r", encoding="utf-8") as f:
        return json.load(f)

# ===== æ ¸å¿ƒ Agent ç±» =====
class RAGAgent:
    def __init__(self, persona=None, persist_dir=None):  # è®¾ç½®ä¸º None ä½¿ç”¨å†…å­˜æ•°æ®åº“
        # åˆå§‹åŒ–æœ¬åœ°å‘é‡æ£€ç´¢
        self.embedder = LocalEmbeddingModel()
        # è®¾ç½® persist_dir ä¸º None ä½¿ç”¨å†…å­˜æ•°æ®åº“
        self.vector_client = chromadb.PersistentClient(path=persist_dir)
        self.collection = self.vector_client.get_or_create_collection(name="dao_knowledge")
        self.history = []

        # ä½¿ç”¨ Streamlit Secrets è·å– OpenAI API å¯†é’¥
        self.openai_client = OpenAI(api_key=st.secrets["openai"]["api_key"])

        # åŠ è½½å¯¼å¸ˆ persona
        self.personas = load_personas()
        if persona is None:
            self.persona = self.personas.get("å­”å­")
        elif isinstance(persona, dict):
            self.persona = persona
        elif isinstance(persona, str):
            self.persona = self.personas.get(persona)
        else:
            raise ValueError("Invalid persona input")

        if not self.persona:
            raise ValueError("è§’è‰² persona åŠ è½½å¤±è´¥")

    def retrieve(self, query, top_k=5):
        embedding = self.embedder.embed_text(query)
        results = self.collection.query(
            query_embeddings=[embedding],
            n_results=top_k
        )
        return list(zip(results["documents"][0], results["metadatas"][0]))

    def ask(self, question):
        context_pairs = self.retrieve(question)
        system_prompt = self.persona["system_prompt"]

        # æ„é€ å¼•ç”¨æ®µè½
        quote_blocks = ""
        for text, meta in context_pairs:
            book = meta.get("title", "æœªçŸ¥ä¹¦ç±").replace(".md", "").replace(".pdf", "")
            chapter = meta.get("chapter_title", "æœªçŸ¥ç« èŠ‚")
            quote_blocks += f"> {text.strip()}\n> â€”â€”ã€Š{book}ã€‹Â·{chapter}\n\n"

        # æ„é€ ç”¨æˆ· prompt
        user_prompt = f"""
                ã€å¼•ç”¨èµ„æ–™ã€‘ï¼š
                {quote_blocks}

                ã€ç”¨æˆ·é—®é¢˜ã€‘ï¼š{question}
                è¯·ä»¥ä½ çš„é£æ ¼å›ç­”ï¼Œå¼•ç”¨èµ„æ–™å†…å®¹ï¼Œä¸å¾—ç¼–é€ ã€‚
                """

        messages = [{"role": "system", "content": system_prompt}]
        for q, a in self.history[-5:]:
            messages.append({"role": "user", "content": q})
            messages.append({"role": "assistant", "content": a})
        messages.append({"role": "user", "content": user_prompt})

        # ä½¿ç”¨ self.openai_client è°ƒç”¨ ChatCompletion
        response = self.openai_client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.7
        )

        answer = response.choices[0].message.content.strip()
        self.history.append((question, answer))
        return answer

# ===== å‘½ä»¤è¡Œæµ‹è¯•å…¥å£ï¼ˆé streamlit æ—¶ä½¿ç”¨ï¼‰ =====
if __name__ == "__main__":
    personas = load_personas()
    persona_id = "å­”å­"
    agent = RAGAgent(persona=persona_id)
    while True:
        question = input("\nğŸ¤– è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼ˆè¾“å…¥ q é€€å‡ºï¼‰ï¼š\n> ")
        if question.lower() in ['q', 'quit', 'exit']:
            break
        answer = agent.ask(question)
        print(f"\nğŸ’¡ å›ç­”ï¼ˆ{persona_id}ï¼‰ï¼š\n{answer}")

print("ğŸ” å½“å‰ OpenAI Key æ¥è‡ª secretsï¼š", st.secrets["openai"]["api_key"])

